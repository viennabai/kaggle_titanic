{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test = pd.read_csv('preprocessed_test.csv')\n",
    "y_final = test['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('preprocessed_test.csv')\n",
    "data = raw_data.drop(['PassengerId'], axis=1)\n",
    "\n",
    "#change some assignments to facilitate dummy variable dropping \n",
    "data['Sex'] = data['Sex'].map({'female':1, 'male':0})\n",
    "data = data.rename({'Sex': 'Is_Female'}, axis=1)\n",
    "data.loc[data.Pclass == 3, 'Pclass'] = 0\n",
    "data.loc[data.Deck == 'Unknown', 'Deck'] = 0\n",
    "\n",
    "#convert to categorical data type \n",
    "for x in data: \n",
    "    data[x] = data[x].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = data['Survived']\n",
    "inputs = data.drop(['Survived'], axis=1)\n",
    "inputs = pd.get_dummies(inputs, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 30)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate out 15% data as final test - do not touch until you're sure you're done\n",
    "X, X_final, Y, y_final = train_test_split(inputs, targets, train_size = .85, random_state=33)\n",
    "\n",
    "#separet out 15% as CV\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, Y, train_size = .85, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model\n",
    "\n",
    "Regularization is applied by default - l2, C=1.0 (set to a really large # to default to no regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(643, 31)\n",
      "0.8506998444790047\n",
      "0.8245614035087719\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver = 'liblinear', C = 10000)\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_cv = sm.add_constant(X_cv)\n",
    "print(X_train.shape)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#accuracy\n",
    "print(model.score(X_train, y_train)) #we see some overfitting\n",
    "print(model.score(X_cv, y_cv))\n",
    "pred = model.predict(X_cv)\n",
    "\n",
    "#there is evidence of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred No</th>\n",
       "      <th>Pred Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual No</th>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Yes</th>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pred No  Pred Yes\n",
       "Actual No        55         5\n",
       "Actual Yes       15        39"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_cv, pred)\n",
    "cm_df = pd.DataFrame(cm, columns=['Pred No', 'Pred Yes'])\n",
    "cm_df = cm_df.rename(index = {0: 'Actual No', 1: 'Actual Yes'})\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.786     0.917     0.846        60\n",
      "           1      0.886     0.722     0.796        54\n",
      "\n",
      "    accuracy                          0.825       114\n",
      "   macro avg      0.836     0.819     0.821       114\n",
      "weighted avg      0.833     0.825     0.822       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_cv, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision = 0.886 (of all the 1's we assigned, 88.6% did survive)\n",
    "recall = 0.722 (of all those who did survive, we only got 72.2% correct)\n",
    "f1 = 0.796\n",
    "accuracy = 0.825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters: {'C': 0.5, 'penalty': 'l1'}\n",
      "accuracy: 0.8243217054263565\n"
     ]
    }
   ],
   "source": [
    "params_grid = {\"C\": [0.1, 0.3, 0.5, 0.7, 0.9, 1, 1.5], \n",
    "               \"penalty\":[\"l1\",\"l2\"]}  #l1 lasso l2 ridge\n",
    "\n",
    "logreg = LogisticRegression(solver = 'liblinear')\n",
    "logreg_cv = GridSearchCV(logreg, params_grid, cv=5, scoring = 'accuracy')\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(f\"tuned hpyerparameters: {logreg_cv.best_params_}\")\n",
    "print(f\"accuracy: {logreg_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(643, 31)\n",
      "0.8289269051321928\n",
      "0.8245614035087719\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver = 'liblinear', C = 0.5, penalty = 'l1')\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_cv = sm.add_constant(X_cv)\n",
    "\n",
    "print(X_train.shape)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#accuracy\n",
    "print(model.score(X_train, y_train)) #we see some overfitting\n",
    "print(model.score(X_cv, y_cv))\n",
    "pred = model.predict(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred No</th>\n",
       "      <th>Pred Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual No</th>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Yes</th>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pred No  Pred Yes\n",
       "Actual No        55         5\n",
       "Actual Yes       15        39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_cv, pred)\n",
    "cm_df = pd.DataFrame(cm, columns=['Pred No', 'Pred Yes'])\n",
    "cm_df = cm_df.rename(index = {0: 'Actual No', 1: 'Actual Yes'})\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.786     0.917     0.846        60\n",
      "           1      0.886     0.722     0.796        54\n",
      "\n",
      "    accuracy                          0.825       114\n",
      "   macro avg      0.836     0.819     0.821       114\n",
      "weighted avg      0.833     0.825     0.822       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_cv, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision = 0.886 (of all the 1's we assigned, 88.6% did survive)\n",
    "recall = 0.722 (of all those who did survive, we only got 72.2% correct)\n",
    "f1 = 0.796\n",
    "accuracy = 0.825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coef</th>\n",
       "      <th>Odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>1.655530</td>\n",
       "      <td>5.235852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Is_Female_1</td>\n",
       "      <td>1.480432</td>\n",
       "      <td>4.394843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>1.398088</td>\n",
       "      <td>4.047454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.792290</td>\n",
       "      <td>2.208448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Deck_D</td>\n",
       "      <td>0.438800</td>\n",
       "      <td>1.550844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Deck_E</td>\n",
       "      <td>0.293123</td>\n",
       "      <td>1.340607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Age_Group_30-39</td>\n",
       "      <td>0.243496</td>\n",
       "      <td>1.275701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fare_Group_7-8</td>\n",
       "      <td>0.145056</td>\n",
       "      <td>1.156104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.066853</td>\n",
       "      <td>1.069138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fare_Group_38+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Deck_A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Deck_B</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Deck_C</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fare_Group_13-25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Deck_F</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fare_Group_25-38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Deck_G</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fare_Group_10.5-13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Family_Size_1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Age_Group_24-29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Age_Group_16-19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Age_Group_20-23</td>\n",
       "      <td>-0.023997</td>\n",
       "      <td>0.976288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>-0.055712</td>\n",
       "      <td>0.945812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Fare_Group_8-10.5</td>\n",
       "      <td>-0.072672</td>\n",
       "      <td>0.929906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Age_Group_40-54</td>\n",
       "      <td>-0.181454</td>\n",
       "      <td>0.834057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>-0.385662</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Age_Group_60+</td>\n",
       "      <td>-0.445697</td>\n",
       "      <td>0.640378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>-1.439027</td>\n",
       "      <td>0.237158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Family_Size_2</td>\n",
       "      <td>-1.713780</td>\n",
       "      <td>0.180183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features      Coef  Odds_ratio\n",
       "1             Pclass_1  1.655530    5.235852\n",
       "7          Is_Female_1  1.480432    4.394843\n",
       "3         Title_Master  1.398088    4.047454\n",
       "2             Pclass_2  0.792290    2.208448\n",
       "27              Deck_D  0.438800    1.550844\n",
       "28              Deck_E  0.293123    1.340607\n",
       "11     Age_Group_30-39  0.243496    1.275701\n",
       "20      Fare_Group_7-8  0.145056    1.156104\n",
       "6            Title_Mrs  0.066853    1.069138\n",
       "19      Fare_Group_38+  0.000000    1.000000\n",
       "24              Deck_A  0.000000    1.000000\n",
       "0            Intercept  0.000000    1.000000\n",
       "25              Deck_B  0.000000    1.000000\n",
       "26              Deck_C  0.000000    1.000000\n",
       "17    Fare_Group_13-25  0.000000    1.000000\n",
       "29              Deck_F  0.000000    1.000000\n",
       "18    Fare_Group_25-38  0.000000    1.000000\n",
       "30              Deck_G  0.000000    1.000000\n",
       "16  Fare_Group_10.5-13  0.000000    1.000000\n",
       "14       Family_Size_1  0.000000    1.000000\n",
       "10     Age_Group_24-29  0.000000    1.000000\n",
       "8      Age_Group_16-19  0.000000    1.000000\n",
       "4           Title_Miss  0.000000    1.000000\n",
       "9      Age_Group_20-23 -0.023997    0.976288\n",
       "22          Embarked_Q -0.055712    0.945812\n",
       "21   Fare_Group_8-10.5 -0.072672    0.929906\n",
       "12     Age_Group_40-54 -0.181454    0.834057\n",
       "23          Embarked_S -0.385662    0.680000\n",
       "13       Age_Group_60+ -0.445697    0.640378\n",
       "5             Title_Mr -1.439027    0.237158\n",
       "15       Family_Size_2 -1.713780    0.180183"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features interpretation \n",
    "feature_names = inputs.columns.values\n",
    "feature_names = np.append(['Intercept'], feature_names)\n",
    "\n",
    "summary = pd.DataFrame(data = feature_names, columns = ['Features'])\n",
    "summary['Coef'] = np.transpose(model.coef_)\n",
    "summary['Odds_ratio'] = np.exp(summary.Coef)\n",
    "summary.sort_values('Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretatin of Odds_ratio:\n",
    "holding other variables constant, how does this feature impact odds compared to default \n",
    "\n",
    "Deck_E: holding everything else constant, odds of survival is almost 5x that of Unknown Deck \n",
    "Deck_G: holding everything else constant, odds of survival is almost 50%worse that of Unknown Deck \n",
    "Is_Female: 4.4x better odds than male \n",
    "As we approach odds_ratio of 1, less explanatory power of the feature -- \n",
    "Deck_A and Title_miss are close to 1 \n",
    "lastly, family_size_2 (5+) means odds of survival is almost 90% worse than traveling Alone \n",
    "\n",
    "Surprises: \n",
    "Pclass_2 odds_ratio is higher than that of Pclass\n",
    "Pclass 2 2.2x more likely than Pclass 3 \n",
    "Pclass 1 66% more likely \n",
    "Family_size_1 (2-4) 25% less good than traveling Alone -- seems to be contraditory to our EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change 1/0 assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict_proba(X_cv)[:,1]\n",
    "pred = [0 if x < 0.4 else 1 for x in pred_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred No</th>\n",
       "      <th>Pred Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual No</th>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Yes</th>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pred No  Pred Yes\n",
       "Actual No        51         9\n",
       "Actual Yes       12        42"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_cv, pred)\n",
    "cm_df = pd.DataFrame(cm, columns=['Pred No', 'Pred Yes'])\n",
    "cm_df = cm_df.rename(index = {0: 'Actual No', 1: 'Actual Yes'})\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.806     0.900     0.850        60\n",
      "           1      0.872     0.759     0.812        54\n",
      "\n",
      "    accuracy                          0.833       114\n",
      "   macro avg      0.839     0.830     0.831       114\n",
      "weighted avg      0.837     0.833     0.832       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_cv, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8401585204755614\n",
      "0.835820895522388\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver = 'liblinear', C = 0.5, penalty = 'l1')\n",
    "X = sm.add_constant(X)\n",
    "X_final = sm.add_constant(X_final)\n",
    "model.fit(X, Y)\n",
    "\n",
    "print(model.score(X, Y)) #we see some overfitting\n",
    "print(model.score(X_final, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sm.add_constant(inputs)\n",
    "\n",
    "pred_proba = model.predict_proba(inputs)[:,1]\n",
    "pred = [0 if x < 0.5 else 1 for x in pred_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.845     0.887     0.866        80\n",
      "           1      0.820     0.759     0.788        54\n",
      "\n",
      "    accuracy                          0.836       134\n",
      "   macro avg      0.833     0.823     0.827       134\n",
      "weighted avg      0.835     0.836     0.835       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_final, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predfinal['PassengerId'] = raw_data\n",
    "predfinal = predfinal[['PassengerId', 'Survived']]\n",
    "predfinal\n",
    "predfinal.to_csv('nn_submit_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(raw_data['PassengerId'].values, columns = ['PassengerId'])\n",
    "submit['Survived'] = pred\n",
    "submit\n",
    "submit.to_csv('log_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score on Kaggle: 0.7799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
